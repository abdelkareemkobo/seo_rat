# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/06_index_tracking.ipynb.

# %% auto #0
__all__ = ['inspect_url_status', 'store_index_status', 'get_index_status', 'get_not_indexed_pages', 'get_not_indexed_by_reason',
           'fetch_sitemap_urls', 'store_all_index_status', 'submit_sitemap', 'get_index_history']

# %% ../nbs/06_index_tracking.ipynb #b28f692b
from sqlmodel import Session, select
from .models import IndexStatus
from .gsc_client import GSCAuth
from googleapiclient.discovery import build
from datetime import datetime
import httpx
from bs4 import BeautifulSoup
import time

# %% ../nbs/06_index_tracking.ipynb #db5cae1f
def inspect_url_status(auth: GSCAuth, site_url: str, page_url: str) -> dict:
    """Inspect URL indexing status from GSC"""
    service = build("searchconsole", "v1", credentials=auth.get_credentials())
    request = {"inspectionUrl": page_url, "siteUrl": site_url, "languageCode": "en-US"}
    response = service.urlInspection().index().inspect(body=request).execute()
    result = response.get("inspectionResult", {}).get("indexStatusResult", {})

    return {
        "verdict": result.get("verdict", "UNKNOWN"),
        "coverage_state": result.get("coverageState"),
        "last_crawl_time": result.get("lastCrawlTime"),
        "indexing_state": result.get("indexingState"),
        "robots_txt_state": result.get("robotsTxtState"),
    }


# %% ../nbs/06_index_tracking.ipynb #4e7493ca
def store_index_status(session: Session, auth: GSCAuth, site_url: str, page_url: str):
    """Inspect and store URL index status as a new history row"""
    status_data = inspect_url_status(auth, site_url, page_url)
    record = IndexStatus(site_url=site_url, page_url=page_url, **status_data)
    session.add(record)
    session.commit()


# %% ../nbs/06_index_tracking.ipynb #e7b6358d
def get_index_status(
    session: Session,
    site_url: str,
    verdict: str | None = None,
) -> list[IndexStatus]:
    """Get latest index status per page"""
    from sqlalchemy import func

    latest = (
        select(IndexStatus.page_url, func.max(IndexStatus.checked_at).label("max_checked"))
        .where(IndexStatus.site_url == site_url)
        .group_by(IndexStatus.page_url)
        .subquery()
    )

    query = select(IndexStatus).join(
        latest,
        (IndexStatus.page_url == latest.c.page_url) &
        (IndexStatus.checked_at == latest.c.max_checked),
    )
    if verdict:
        query = query.where(IndexStatus.verdict == verdict)
    return session.exec(query).all()


# %% ../nbs/06_index_tracking.ipynb #d4022577
def get_not_indexed_pages(session: Session, site_url: str) -> list[IndexStatus]:
    """Get pages that are not indexed (latest status only)"""
    return [p for p in get_index_status(session, site_url) if p.verdict != "PASS"]


# %% ../nbs/06_index_tracking.ipynb #6545d5a7
def get_not_indexed_by_reason(session: Session, site_url: str) -> dict[str, list[IndexStatus]]:
    """Group not-indexed pages by their coverage state reason"""
    pages = get_not_indexed_pages(session, site_url)
    grouped = {}
    for page in pages:
        reason = page.coverage_state or "Unknown"
        grouped.setdefault(reason, []).append(page)
    return grouped


# %% ../nbs/06_index_tracking.ipynb #73794973
def fetch_sitemap_urls(sitemap_url: str) -> list[str]:
    """Fetch all URLs from sitemap XML"""
    response = httpx.get(sitemap_url)
    soup = BeautifulSoup(response.text, "xml")
    return [loc.text for loc in soup.find_all("loc")]


# %% ../nbs/06_index_tracking.ipynb #f514af6b
def store_all_index_status(
    session: Session,
    auth: GSCAuth,
    site_url: str,
    sitemap_url: str,
) -> dict:
    """Check and store index status for all pages in sitemap"""
    urls = fetch_sitemap_urls(sitemap_url)
    total = len(urls)
    results = {"successful": [], "failed": []}

    for i, url in enumerate(urls, 1):
        print(f"Checking {i}/{total}: {url}")
        try:
            store_index_status(session, auth, site_url, url)
            results["successful"].append(url)
        except Exception as e:
            results["failed"].append({"url": url, "error": str(e)})
        time.sleep(1)

    return results

# %% ../nbs/06_index_tracking.ipynb #178fc4c9
def submit_sitemap(auth: GSCAuth, site_url: str, sitemap_url: str):
    """Submit sitemap to Google Search Console"""
    service = build("searchconsole", "v1", credentials=auth.get_credentials())
    service.sitemaps().submit(siteUrl=site_url, feedpath=sitemap_url).execute()
    print(f"Submitted: {sitemap_url}")


# %% ../nbs/06_index_tracking.ipynb #29f908d4
def get_index_history(session: Session, page_url: str) -> list[IndexStatus]:
    """Get full index status history for a page"""
    return session.exec(
        select(IndexStatus)
        .where(IndexStatus.page_url == page_url)
        .order_by(IndexStatus.checked_at.desc())
    ).all()
