{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp store_gsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "from fastapi import FastAPI, HTTPException, Query,APIRouter\n",
    "from typing import Dict, List, Optional\n",
    "from datetime import datetime, timedelta\n",
    "from googleapiclient.discovery import build\n",
    "import asyncio\n",
    "from seo_rat.gsc_db import SearchConsoleDB\n",
    "from seo_rat.fast_gsc import  app\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "store_router = APIRouter(prefix=\"/store\", tags=[\"Storage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from seo_rat.fast_gsc import  GSCAuth\n",
    "auth = GSCAuth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "db = SearchConsoleDB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from bson import ObjectId\n",
    "\n",
    "def serialize_mongodb_doc(doc):\n",
    "    \"\"\"Helper function to serialize MongoDB documents\"\"\"\n",
    "    if isinstance(doc, dict):\n",
    "        return {k: serialize_mongodb_doc(v) for k, v in doc.items()}\n",
    "    elif isinstance(doc, list):\n",
    "        return [serialize_mongodb_doc(item) for item in list(doc)]\n",
    "    elif isinstance(doc, ObjectId):\n",
    "        return str(doc)\n",
    "    elif isinstance(doc, datetime):\n",
    "        return doc.isoformat()\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pydantic import BaseModel, Field\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "\n",
    "class StoreAnalyticsResponse(BaseModel):\n",
    "    \"\"\"Response model for analytics storage\n",
    "\n",
    "    Attributes:\n",
    "        message: Status message\n",
    "        date: Date of stored data\n",
    "        dimensions: List of dimensions stored\n",
    "        records_count: Optional number of records stored\n",
    "    \"\"\"\n",
    "\n",
    "    message: str\n",
    "    date: str\n",
    "    dimensions: List[str]\n",
    "    records_count: Optional[int] = None\n",
    "\n",
    "\n",
    "class AnalyticsDocument(BaseModel):\n",
    "    \"\"\"MongoDB document structure for analytics data\n",
    "\n",
    "    Attributes:\n",
    "        site_url: Website URL\n",
    "        date: Date of data\n",
    "        dimensions: Dictionary of dimension values\n",
    "        metrics: Dictionary of metric values\n",
    "        timestamp: Time of storage\n",
    "    \"\"\"\n",
    "\n",
    "    site_url: str\n",
    "    date: str\n",
    "    dimensions: Dict[str, str]\n",
    "    metrics: Dict[str, float]\n",
    "    timestamp: datetime\n",
    "\n",
    "\n",
    "@store_router.get(\n",
    "    \"/store-analytics/{site_url}\",\n",
    "    response_model=StoreAnalyticsResponse,\n",
    "    summary=\"Store analytics data\",\n",
    ")\n",
    "async def store_site_analytics(\n",
    "    site_url: str,  # Website URL to analyze\n",
    "    date: str = Query(\n",
    "        default=datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "        description=\"Date to store (YYYY-MM-DD)\",\n",
    "    ),\n",
    ") -> StoreAnalyticsResponse:\n",
    "    \"\"\"Store Google Search Console analytics data with all dimensions.\n",
    "\n",
    "    Retrieves and stores analytics data for a specific date, including all\n",
    "    dimension combinations (query, page, country, device). Handles data\n",
    "    availability delay and prevents duplicate storage.\n",
    "\n",
    "    Args:\n",
    "        site_url: Website to analyze\n",
    "        date: Date to store data for (YYYY-MM-DD)\n",
    "\n",
    "    Returns:\n",
    "        StoreAnalyticsResponse containing:\n",
    "        - Status message\n",
    "        - Date processed\n",
    "        - Dimensions stored\n",
    "        - Number of records stored\n",
    "\n",
    "    Raises:\n",
    "        HTTPException:\n",
    "            - 401 if not authenticated\n",
    "            - 500 for API or database errors\n",
    "\n",
    "    Examples:\n",
    "        >>> # Store today's data (adjusted for delay)\n",
    "        >>> response = await store_site_analytics(\n",
    "        ...     \"sc-domain:example.com\"\n",
    "        ... )\n",
    "\n",
    "        >>> # Store data for specific date\n",
    "        >>> response = await store_site_analytics(\n",
    "        ...     \"sc-domain:example.com\",\n",
    "        ...     date=\"2024-01-01\"\n",
    "        ... )\n",
    "\n",
    "    Notes:\n",
    "        - Google Search Console data has a 3-day delay\n",
    "        - Maximum 5000 records per request\n",
    "        - Stores all dimension combinations\n",
    "        - Prevents duplicate storage for same date\n",
    "    \"\"\"\n",
    "    if not auth.credentials:\n",
    "        raise HTTPException(\n",
    "            status_code=401, detail=\"Not authenticated. Please visit /login first.\"\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        # Validate and check date availability\n",
    "        target_date = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "        today = datetime.now()\n",
    "        latest_available = today - timedelta(days=2)\n",
    "\n",
    "        if target_date.date() >= latest_available.date():\n",
    "            return StoreAnalyticsResponse(\n",
    "                message=\"Data not yet available\",\n",
    "                date=date,\n",
    "                dimensions=[],\n",
    "                records_count=0,\n",
    "            )\n",
    "\n",
    "        # Initialize service with auth credentials\n",
    "        service = build(\"searchconsole\", \"v1\", credentials=auth.credentials)\n",
    "\n",
    "        # Request data with all dimensions\n",
    "        response = (\n",
    "            service.searchanalytics()\n",
    "            .query(\n",
    "                siteUrl=site_url,\n",
    "                body={\n",
    "                    \"startDate\": date,\n",
    "                    \"endDate\": date,\n",
    "                    \"dimensions\": [\"query\", \"page\", \"country\", \"device\"],\n",
    "                    \"rowLimit\": 5000,\n",
    "                },\n",
    "            )\n",
    "            .execute()\n",
    "        )\n",
    "\n",
    "        # Process and store data\n",
    "        if \"rows\" in response:\n",
    "            documents = []\n",
    "            for row in response[\"rows\"]:\n",
    "                doc = AnalyticsDocument(\n",
    "                    site_url=site_url,\n",
    "                    date=date,\n",
    "                    dimensions={\n",
    "                        \"query\": row[\"keys\"][0],\n",
    "                        \"page\": row[\"keys\"][1],\n",
    "                        \"country\": row[\"keys\"][2],\n",
    "                        \"device\": row[\"keys\"][3],\n",
    "                    },\n",
    "                    metrics={\n",
    "                        \"clicks\": row[\"clicks\"],\n",
    "                        \"impressions\": row[\"impressions\"],\n",
    "                        \"ctr\": row[\"ctr\"],\n",
    "                        \"position\": row[\"position\"],\n",
    "                    },\n",
    "                    timestamp=datetime.now(),\n",
    "                )\n",
    "                documents.append(doc.dict())\n",
    "\n",
    "            if documents:\n",
    "                db.db.analytics.insert_many(documents)\n",
    "\n",
    "            return StoreAnalyticsResponse(\n",
    "                message=f\"Successfully stored analytics data\",\n",
    "                date=date,\n",
    "                dimensions=[\"query\", \"page\", \"country\", \"device\"],\n",
    "                records_count=len(documents),\n",
    "            )\n",
    "\n",
    "        return StoreAnalyticsResponse(\n",
    "            message=\"No data found for the specified date\",\n",
    "            date=date,\n",
    "            dimensions=[],\n",
    "            records_count=0,\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        raise HTTPException(\n",
    "            status_code=500, detail=f\"Failed to store analytics data: {str(e)}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any\n",
    "import asyncio\n",
    "\n",
    "\n",
    "class DateResult(BaseModel):\n",
    "    \"\"\"Result for a single date's processing\n",
    "\n",
    "    Attributes:\n",
    "        date: Date processed\n",
    "        records: Number of records stored\n",
    "    \"\"\"\n",
    "\n",
    "    date: str\n",
    "    records: int\n",
    "\n",
    "\n",
    "class DateError(BaseModel):\n",
    "    \"\"\"Error information for a failed date\n",
    "\n",
    "    Attributes:\n",
    "        date: Date that failed\n",
    "        reason: Error message\n",
    "    \"\"\"\n",
    "\n",
    "    date: str\n",
    "    reason: str\n",
    "\n",
    "\n",
    "class RangeAnalyticsResponse(BaseModel):\n",
    "    \"\"\"Response model for range analytics storage\n",
    "\n",
    "    Attributes:\n",
    "        successful_dates: List of successfully processed dates\n",
    "        failed_dates: List of dates that failed\n",
    "        total_records: Total number of records stored\n",
    "        progress: Current progress information\n",
    "    \"\"\"\n",
    "\n",
    "    successful_dates: List[DateResult]\n",
    "    failed_dates: List[DateError]\n",
    "    total_records: int\n",
    "    progress: Dict[str, Any]\n",
    "\n",
    "\n",
    "@store_router.get(\n",
    "    \"/store-analytics-range/{site_url}\",\n",
    "    response_model=RangeAnalyticsResponse,\n",
    "    summary=\"Store analytics for date range\",\n",
    ")\n",
    "async def store_site_analytics_range(\n",
    "    site_url: str,\n",
    "    start_date: str = Query(\n",
    "        default=\"2023-12-29\", description=\"Start date (YYYY-MM-DD)\"\n",
    "    ),\n",
    "    end_date: str = Query(default=\"2024-12-06\", description=\"End date (YYYY-MM-DD)\"),\n",
    ") -> RangeAnalyticsResponse:\n",
    "    \"\"\"Store Google Search Console analytics data for a date range.\n",
    "\n",
    "    Retrieves and stores analytics data for each date in the range,\n",
    "    with progress tracking and error handling. Includes automatic\n",
    "    date adjustment for data availability delay.\n",
    "\n",
    "    Args:\n",
    "        site_url: Website to analyze\n",
    "        start_date: Start date of range (YYYY-MM-DD)\n",
    "        end_date: End date of range (YYYY-MM-DD)\n",
    "\n",
    "    Returns:\n",
    "        RangeAnalyticsResponse containing:\n",
    "        - Successfully processed dates\n",
    "        - Failed dates with reasons\n",
    "        - Total records stored\n",
    "        - Progress information\n",
    "\n",
    "    Raises:\n",
    "        HTTPException:\n",
    "            - 401 if not authenticated\n",
    "            - 500 for API or database errors\n",
    "\n",
    "    Examples:\n",
    "        >>> # Store last month's data\n",
    "        >>> response = await store_site_analytics_range(\n",
    "        ...     \"sc-domain:example.com\",\n",
    "        ...     start_date=\"2024-01-01\",\n",
    "        ...     end_date=\"2024-01-31\"\n",
    "        ... )\n",
    "\n",
    "    Notes:\n",
    "        - Processes one day at a time\n",
    "        - Includes 1-second delay between requests\n",
    "        - Handles rate limits\n",
    "        - Maximum 5000 records per day\n",
    "        - Automatically adjusts for 3-day data delay\n",
    "    \"\"\"\n",
    "    if not auth.credentials:\n",
    "        raise HTTPException(\n",
    "            status_code=401, detail=\"Not authenticated. Please visit /login first.\"\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        # Initialize service with auth credentials\n",
    "        service = build(\"searchconsole\", \"v1\", credentials=auth.credentials)\n",
    "\n",
    "        # Validate dates\n",
    "        start = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "        end = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "        today = datetime.now()\n",
    "        latest_available = today - timedelta(days=3)\n",
    "\n",
    "        # Adjust end date for data availability\n",
    "        if end.date() >= latest_available.date():\n",
    "            end = latest_available\n",
    "\n",
    "        # Initialize results\n",
    "        results = RangeAnalyticsResponse(\n",
    "            successful_dates=[],\n",
    "            failed_dates=[],\n",
    "            total_records=0,\n",
    "            progress={\n",
    "                \"total_days\": (end - start).days + 1,\n",
    "                \"processed_days\": 0,\n",
    "                \"current_date\": None,\n",
    "                \"percentage_complete\": 0,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        # Process each day\n",
    "        current_date = start\n",
    "        while current_date <= end:\n",
    "            date_str = current_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "            # Update progress\n",
    "            results.progress.update(\n",
    "                {\n",
    "                    \"current_date\": date_str,\n",
    "                    \"processed_days\": (current_date - start).days + 1,\n",
    "                    \"percentage_complete\": round(\n",
    "                        ((current_date - start).days + 1)\n",
    "                        / ((end - start).days + 1)\n",
    "                        * 100,\n",
    "                        2,\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                # Get data for current date\n",
    "                response = (\n",
    "                    service.searchanalytics()\n",
    "                    .query(\n",
    "                        siteUrl=site_url,\n",
    "                        body={\n",
    "                            \"startDate\": date_str,\n",
    "                            \"endDate\": date_str,\n",
    "                            \"dimensions\": [\"query\", \"page\", \"country\", \"device\"],\n",
    "                            \"rowLimit\": 5000,\n",
    "                        },\n",
    "                    )\n",
    "                    .execute()\n",
    "                )\n",
    "\n",
    "                if \"rows\" in response:\n",
    "                    # Store data\n",
    "                    documents = [\n",
    "                        AnalyticsDocument(\n",
    "                            site_url=site_url,\n",
    "                            date=date_str,\n",
    "                            dimensions={\n",
    "                                \"query\": row[\"keys\"][0],\n",
    "                                \"page\": row[\"keys\"][1],\n",
    "                                \"country\": row[\"keys\"][2],\n",
    "                                \"device\": row[\"keys\"][3],\n",
    "                            },\n",
    "                            metrics={\n",
    "                                \"clicks\": row[\"clicks\"],\n",
    "                                \"impressions\": row[\"impressions\"],\n",
    "                                \"ctr\": row[\"ctr\"],\n",
    "                                \"position\": row[\"position\"],\n",
    "                            },\n",
    "                            timestamp=datetime.now(),\n",
    "                        ).dict()\n",
    "                        for row in response[\"rows\"]\n",
    "                    ]\n",
    "\n",
    "                    if documents:\n",
    "                        # Check for existing data\n",
    "                        db.db.analytics.delete_many(\n",
    "                            {\"site_url\": site_url, \"date\": date_str}\n",
    "                        )\n",
    "                        # Insert new data\n",
    "                        db.db.analytics.insert_many(documents)\n",
    "                        results.successful_dates.append(\n",
    "                            DateResult(date=date_str, records=len(documents))\n",
    "                        )\n",
    "                        results.total_records += len(documents)\n",
    "                    else:\n",
    "                        results.failed_dates.append(\n",
    "                            DateError(date=date_str, reason=\"No data found\")\n",
    "                        )\n",
    "\n",
    "            except Exception as e:\n",
    "                results.failed_dates.append(DateError(date=date_str, reason=str(e)))\n",
    "\n",
    "            # Move to next day\n",
    "            current_date += timedelta(days=1)\n",
    "            await asyncio.sleep(1)  # Rate limit delay\n",
    "\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        raise HTTPException(\n",
    "            status_code=500, detail=f\"Failed to store range data: {str(e)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@store_router.get(\"/debug-storage/{site_url}\")\n",
    "async def debug_storage(\n",
    "    site_url: str,\n",
    "    date: str = Query(default=datetime.now().strftime('%Y-%m-%d'))\n",
    "):\n",
    "    \"\"\"Debug storage for a specific date\"\"\"\n",
    "    try:\n",
    "        # Add sc-domain: prefix if not present\n",
    "        if not site_url.startswith('sc-domain:'):\n",
    "            site_url = f'sc-domain:{site_url}'\n",
    "            \n",
    "        # Query for specific date\n",
    "        date_docs = list(db.db.analytics.find({\n",
    "            'site_url': site_url,\n",
    "            'date': date\n",
    "        }))\n",
    "        \n",
    "        # Serialize documents\n",
    "        serialized_docs = [serialize_mongodb_doc(doc) for doc in date_docs]\n",
    "        \n",
    "        return {\n",
    "            \"site_url\": site_url,\n",
    "            \"date\": date,\n",
    "            \"total_documents\": len(serialized_docs),\n",
    "            \"documents\": serialized_docs,\n",
    "            \"dimension_types\": list(set(doc['dimension_type'] for doc in date_docs)),\n",
    "            \"metrics_summary\": {\n",
    "                \"total_clicks\": sum(doc['metrics']['clicks'] for doc in date_docs),\n",
    "                \"total_impressions\": sum(doc['metrics']['impressions'] for doc in date_docs),\n",
    "                \"average_position\": sum(doc['metrics']['position'] for doc in date_docs) / len(date_docs) if date_docs else 0\n",
    "            }\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Debug error: {str(e)}\")  # Print error for debugging\n",
    "        raise HTTPException(status_code=500, detail=f\"Database error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from bson import ObjectId\n",
    "import json\n",
    "\n",
    "class JSONEncoder(json.JSONEncoder):\n",
    "    def default(self, o):\n",
    "        if isinstance(o, ObjectId):\n",
    "            return str(o)\n",
    "        return super().default(o)\n",
    "\n",
    "@store_router.get(\"/debug-mongodb\")\n",
    "async def debug_mongodb():\n",
    "    \"\"\"Debug MongoDB contents\"\"\"\n",
    "    try:\n",
    "        # Get database information\n",
    "        collections = db.db.list_collection_names()\n",
    "        \n",
    "        # Get counts for each collection\n",
    "        collection_stats = {}\n",
    "        for collection in collections:\n",
    "            # Get a sample document and convert ObjectId to string\n",
    "            sample_doc = db.db[collection].find_one()\n",
    "            if sample_doc and '_id' in sample_doc:\n",
    "                sample_doc['_id'] = str(sample_doc['_id'])\n",
    "            \n",
    "            collection_stats[collection] = {\n",
    "                \"count\": db.db[collection].count_documents({}),\n",
    "                \"sample\": sample_doc,\n",
    "                \"unique_sites\": list(db.db[collection].distinct(\"site_url\")),\n",
    "                \"unique_dates\": list(db.db[collection].distinct(\"date\"))\n",
    "            }\n",
    "            \n",
    "        return {\n",
    "            \"database_name\": db.db.name,\n",
    "            \"collections\": list(collections),\n",
    "            \"stats\": collection_stats\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Debug error: {str(e)}\")  # Print error for debugging\n",
    "        raise HTTPException(status_code=500, detail=f\"MongoDB error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "app.include_router(store_router)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
