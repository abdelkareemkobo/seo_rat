{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83b76427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp content_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49f44ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import re\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "from urllib.parse import urlparse\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dea1f21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | test\n",
    "from fastcore.test import test_eq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9764a51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def parse_metadata(content: str) -> Dict:\n",
    "    \"\"\"Extract metadata from content frontmatter\"\"\"\n",
    "    yaml_section = content.split(\"---\")[1]\n",
    "    return yaml.safe_load(yaml_section)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "117726c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | test\n",
    "# Test Parse metadat\n",
    "with open(\"../sample/example.md\", \"r\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "metadata = parse_metadata(content)\n",
    "# | test\n",
    "\n",
    "with open(\"../sample/example.md\", \"r\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "metadata = parse_metadata(content)\n",
    "test_eq(metadata[\"title\"], \"Kareem Elkhateb SEO Trend Example\")\n",
    "test_eq(str(metadata[\"publishDate\"]), \"2024-01-27\")\n",
    "test_eq(metadata[\"tags\"], [\"Astrojs\", \"Rust\", \"C++\", \"C#\", \"Camel_Space\", \"Horse Case\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9460e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def remove_metadata(content: str) -> str:\n",
    "    \"\"\"Remove frontmatter from content\"\"\"\n",
    "    end = content.find(\"---\", 3)\n",
    "    return content[end + 3 :].strip() if end != -1 else content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a5f68e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# This is me Kareem\\n\\n# This is Kareem Also\\n\\nMy name is kareem and i am going to help all you!\\n\\n## How do you know me!\\n\\nI know you by just saying you are just a shity person!\\n\\n## oh no! iron man!\\n\\n![Iron man photo](~/assets/images/28.png)\\nThis is a fancy photo of Iron man!!\\n\\nIf you want to call IronMan you can find him in: +01013646887 and **+966503139675** there is also 01005134688 .\\nAre you series!\\nThe Hulk is here!\\n\\n## References\\n\\n[main_website](https://emdadelgaz.com)\\n[main_website_again](https://emdadelgaz.com)\\n[about_website](https://emdadelgaz/about.com)\\n[contact_page](http://emdadelgaz/contact.net)\\n[awazly_website](https://awazly.com/)\\n\\n### Books\\n\\n1. Clean code\\n2. Data Integartions\\n3. Batman\\n\\n#### nbdev is super cool!\\n\\n##### Test Deriven Developement is a life changing!\\n\\n###### I am an Love with best girl in the whole world!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | test\n",
    "# Test Remove metadata\n",
    "content = remove_metadata(content)\n",
    "content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "657150ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def extract_headers(file_path: str) -> List[Dict]:\n",
    "    \"\"\"Extract all headers with metadata\"\"\"\n",
    "    headings = []\n",
    "    with open(file_path, \"r\") as file:\n",
    "        for line_number, line in enumerate(file, start=1):\n",
    "            line = line.strip()\n",
    "            for level in range(1, 7):\n",
    "                prefix = \"#\" * level + \" \"\n",
    "                if line.startswith(prefix):\n",
    "                    content = line.strip(\"#\").strip()\n",
    "                    headings.append(\n",
    "                        {\n",
    "                            \"type\": f\"h{level}\",\n",
    "                            \"line_number\": line_number,\n",
    "                            \"content\": content,\n",
    "                            \"length\": len(content),\n",
    "                        }\n",
    "                    )\n",
    "                    break\n",
    "    return headings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ecd80692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | test\n",
    "headers = extract_headers(\"../sample/example.md\")\n",
    "test_eq(len([h for h in headers if h[\"type\"] == \"h1\"]), 2)\n",
    "test_eq(headers[0][\"content\"], \"This is me Kareem\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc56687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def extract_links(content: str) -> Dict[str, Dict]:\n",
    "    \"\"\"Extract all links with metadata\"\"\"\n",
    "    links = {}\n",
    "    lines = content.split(\"\\n\")\n",
    "    for line_number, line in enumerate(lines, start=1):\n",
    "        for match in re.finditer(r\"\\[(.*?)\\]\\((.*?)\\)\", line):\n",
    "            title, url = match.groups()\n",
    "            if url not in links:\n",
    "                links[url] = {\"titles\": [], \"lines\": []}\n",
    "            links[url][\"titles\"].append(title)\n",
    "            links[url][\"lines\"].append(line_number)\n",
    "    return links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9ba1c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | test\n",
    "links = extract_links(content)\n",
    "test_eq(\"https://emdadelgaz.com\" in links, True)\n",
    "test_eq(\"https://awazly.com/\" in links, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "902e3a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def extract_images(content: str) -> List[Dict]:\n",
    "    \"\"\"Extract images with alt text\"\"\"\n",
    "    matches = re.findall(r\"\\!\\[(.*?)\\]\\((.*?)\\)\", content)\n",
    "    return [{\"alt_text\": alt, \"url\": url} for alt, url in matches]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "409402ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | test\n",
    "images = extract_images(content)\n",
    "test_eq(len(images), 1)\n",
    "test_eq(images[0][\"alt_text\"], \"Iron man photo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92e2970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def filter_internal_links(urls: List[str], domain: str) -> List[str]:\n",
    "    \"\"\"Filter for internal links only\"\"\"\n",
    "    return [url for url in urls if urlparse(url).netloc == domain]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d120d701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def filter_external_links(urls: List[str], domain: str) -> List[str]:\n",
    "    \"\"\"Filter for external links (excluding images)\"\"\"\n",
    "    image_exts = (\".png\", \".jpg\", \".jpeg\", \".gif\", \".bmp\", \".svg\", \".webp\")\n",
    "    return [\n",
    "        url\n",
    "        for url in urls\n",
    "        if urlparse(url).netloc != domain and not url.lower().endswith(image_exts)\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67e05771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def normalize_text(text: str) -> str:\n",
    "    \"\"\"Normalize text by removing extra whitespace\"\"\"\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd856f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def detect_phone_numbers(text: str) -> List[str]:\n",
    "    \"\"\"Extract phone numbers from text\"\"\"\n",
    "    phone_regex = re.compile(r\"(\\+\\d{1,3})?\\s*?(\\d{3})\\s*?(\\d{3})\\s*?(\\d{3,4})\")\n",
    "    groups = phone_regex.findall(text)\n",
    "    return [\"\".join(g) for g in groups]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccbfd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['+01013646887', '+966503139675', '0100513468']\n"
     ]
    }
   ],
   "source": [
    "# | test\n",
    "phones = detect_phone_numbers(content)\n",
    "test_eq(\"+966503139675\" in phones, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b08ed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def calculate_similarity(text1: str, text2: str) -> float:\n",
    "    \"\"\"Calculate similarity ratio between two texts\"\"\"\n",
    "    from difflib import SequenceMatcher\n",
    "\n",
    "    return SequenceMatcher(None, text1, text2).ratio()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21534583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def get_file_paths(pattern: str) -> List[str]:\n",
    "    \"\"\"Get file paths matching pattern\"\"\"\n",
    "    import glob\n",
    "\n",
    "    return glob.glob(pattern, recursive=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def get_file_name(file_path: str) -> str:\n",
    "    \"\"\"Extract filename without extension from path\"\"\"\n",
    "    return Path(file_path).stem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4094fee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def get_markdown_files(directory: str) -> List[str]:\n",
    "    \"\"\"Get all markdown filenames (without extension) from directory\"\"\"\n",
    "    import os\n",
    "\n",
    "    return [\n",
    "        f.replace(\".md\", \"\")\n",
    "        for f in os.listdir(directory)\n",
    "        if f.endswith(\".md\") and f != \".obsidian\"\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6913bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def arabic_to_slug(text: str) -> str:\n",
    "    \"\"\"Convert Arabic text to URL-friendly slug\"\"\"\n",
    "    char_map = {\n",
    "        \"ا\": \"a\",\n",
    "        \"ب\": \"b\",\n",
    "        \"ت\": \"t\",\n",
    "        \"ث\": \"th\",\n",
    "        \"ج\": \"j\",\n",
    "        \"ح\": \"h\",\n",
    "        \"خ\": \"kh\",\n",
    "        \"د\": \"d\",\n",
    "        \"ذ\": \"th\",\n",
    "        \"ر\": \"r\",\n",
    "        \"ز\": \"z\",\n",
    "        \"س\": \"s\",\n",
    "        \"ش\": \"sh\",\n",
    "        \"ص\": \"s\",\n",
    "        \"ض\": \"d\",\n",
    "        \"ط\": \"t\",\n",
    "        \"ظ\": \"z\",\n",
    "        \"ع\": \"\",\n",
    "        \"غ\": \"gh\",\n",
    "        \"ف\": \"f\",\n",
    "        \"ق\": \"q\",\n",
    "        \"ك\": \"k\",\n",
    "        \"ل\": \"l\",\n",
    "        \"م\": \"m\",\n",
    "        \"ن\": \"n\",\n",
    "        \"ه\": \"h\",\n",
    "        \"و\": \"w\",\n",
    "        \"ي\": \"y\",\n",
    "        \"ة\": \"h\",\n",
    "        \" \": \"-\",\n",
    "    }\n",
    "\n",
    "    slug = \"\".join(char_map.get(c, c) for c in text.strip().lower())\n",
    "    while \"--\" in slug:\n",
    "        slug = slug.replace(\"--\", \"-\")\n",
    "    return slug.strip(\"-\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e334816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def map_files_to_slugs(directory: str) -> Dict[str, str]:\n",
    "    \"\"\"Map markdown filenames to URL slugs\"\"\"\n",
    "    files = get_markdown_files(directory)\n",
    "    return {filename: arabic_to_slug(filename) for filename in files}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480617f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc56f66b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
