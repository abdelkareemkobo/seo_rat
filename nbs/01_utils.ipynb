{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n",
    "Some util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import re\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from difflib import SequenceMatcher\n",
    "from urllib.parse import urlparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def exclude_front_matter(content: str) -> str:\n",
    "    \"\"\"Remove front matter from markdown content\"\"\"\n",
    "    front_matter_end = content.find('---', 3)\n",
    "    if front_matter_end != -1:\n",
    "        return content[front_matter_end + 3:].strip()\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# | export\n",
    "def normalize_text(text: str) -> str:\n",
    "    \"\"\"Normalize text by removing extra whitespace\"\"\"\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# | export\n",
    "def extract_frontmatter(md_content: str) -> Tuple[str, str, str, str, List[str]]:\n",
    "    \"\"\"Extract metadata from markdown frontmatter\n",
    "    Returns: title, publishDate, excerpt, image, tags\"\"\"\n",
    "    # Extract YAML front matter\n",
    "    yaml_front_matter = md_content.split(\"---\")[1]\n",
    "    # Load YAML front matter\n",
    "    front_matter_data = yaml.safe_load(yaml_front_matter)\n",
    "    \n",
    "    return (\n",
    "        front_matter_data.get(\"title\"),\n",
    "        front_matter_data.get(\"publishDate\"),\n",
    "        front_matter_data.get(\"excerpt\"),\n",
    "        front_matter_data.get('image'),\n",
    "        front_matter_data.get(\"tags\", [])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# | export\n",
    "def extract_markdown_urls_with_tags(md_content: str) -> Dict[str, Dict]:\n",
    "    \"\"\"Extract URLs and their metadata from markdown content\"\"\"\n",
    "    markdown_urls = {}\n",
    "    lines = md_content.split('\\n')\n",
    "    for line_number, line in enumerate(lines, start=1):\n",
    "        urls = re.finditer(r'\\[(.*?)\\]\\((.*?)\\)', line)\n",
    "        for match in urls:\n",
    "            title = match.group(1)\n",
    "            url = match.group(2)\n",
    "            if url not in markdown_urls:\n",
    "                markdown_urls[url] = {'titles': [], 'lines': []}\n",
    "            markdown_urls[url]['titles'].append(title)\n",
    "            markdown_urls[url]['lines'].append(line_number)\n",
    "    return markdown_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# | export\n",
    "def extract_markdown_images(file_content: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"Extract images and their alt text from markdown content\"\"\"\n",
    "    image_pattern = r'\\!\\[(.*?)\\]\\((.*?)\\)'\n",
    "    matches = re.findall(image_pattern, file_content)\n",
    "    return [{'alt_text': alt_text, 'url': url} for alt_text, url in matches]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def detect_numbers(text: str) -> List[str]:\n",
    "    \"\"\"Extract phone numbers from text\"\"\"\n",
    "    phone_regex = re.compile(r\"(\\+420)?\\s*?(\\d{3})\\s*?(\\d{3})\\s*?(\\d{3})\")\n",
    "    groups = phone_regex.findall(text)\n",
    "    return [\"\".join(g) for g in groups]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# | export\n",
    "def calculate_similarity(text1: str, text2: str) -> float:\n",
    "    \"\"\"Calculate similarity ratio between two texts\"\"\"\n",
    "    return SequenceMatcher(None, text1, text2).ratio()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# | export\n",
    "def get_file_paths(file_path):\n",
    "    \"\"\"\n",
    "    get the file paths\n",
    "    \"\"\"\n",
    "\n",
    "    return glob.glob(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def get_internal_urls(urls, target_domain):\n",
    "    \"\"\"\n",
    "    Get Internal URLs from URls\n",
    "    by the target domain\n",
    "    \"\"\"\n",
    "    related_urls = []\n",
    "    for url in urls:\n",
    "        parsed_url = urlparse(url)\n",
    "        if (\n",
    "            parsed_url.netloc == target_domain\n",
    "            or parsed_url.netloc == target_domain.split(\".\")[0]\n",
    "        ):\n",
    "            related_urls.append(url)\n",
    "    return related_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def get_file_name(file_path):\n",
    "    \"\"\"get the file name\"\"\"\n",
    "    return file_path.split(\"/\")[-1][:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def get_external_urls(urls, target_domain):\n",
    "    \"\"\"\n",
    "    Return the number of Internal Urls from markdown content by Target Domain\n",
    "    \"\"\"\n",
    "    related_urls = []\n",
    "    for url in urls:\n",
    "        parsed_url = urlparse(url)\n",
    "        if (\n",
    "            not parsed_url.netloc == target_domain\n",
    "            and not parsed_url.netloc == target_domain.split(\".\")[0]\n",
    "            and not any(\n",
    "                parsed_url.path.lower().endswith(ext)\n",
    "                for ext in (\".png\", \".jpg\", \".jpeg\", \".gif\", \".bmp\", \".svg\", \".webp\")\n",
    "            )\n",
    "        ):\n",
    "            related_urls.append(url)\n",
    "    return related_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def get_heads_info(file_path):\n",
    "    \"\"\"\n",
    "    Get the Number of Headings for each type with the line number, content, and length\n",
    "    \"\"\"\n",
    "    headings = []\n",
    "\n",
    "    with open(file_path, \"r\") as file:\n",
    "        for line_number, line in enumerate(file, start=1):\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"# \"):\n",
    "                headings.append(\n",
    "                    {\n",
    "                        \"type\": \"h1\",\n",
    "                        \"line_number\": line_number,\n",
    "                        \"content\": line.strip(\"# \").strip(),\n",
    "                        \"length\": len(line.strip(\"# \").strip()),\n",
    "                    }\n",
    "                )\n",
    "            elif line.startswith(\"## \"):\n",
    "                headings.append(\n",
    "                    {\n",
    "                        \"type\": \"h2\",\n",
    "                        \"line_number\": line_number,\n",
    "                        \"content\": line.strip(\"## \").strip(),\n",
    "                        \"length\": len(line.strip(\"## \").strip()),\n",
    "                    }\n",
    "                )\n",
    "            elif line.startswith(\"### \"):\n",
    "                headings.append(\n",
    "                    {\n",
    "                        \"type\": \"h3\",\n",
    "                        \"line_number\": line_number,\n",
    "                        \"content\": line.strip(\"### \").strip(),\n",
    "                        \"length\": len(line.strip(\"### \").strip()),\n",
    "                    }\n",
    "                )\n",
    "            elif line.startswith(\"#### \"):\n",
    "                headings.append(\n",
    "                    {\n",
    "                        \"type\": \"h4\",\n",
    "                        \"line_number\": line_number,\n",
    "                        \"content\": line.strip(\"#### \").strip(),\n",
    "                        \"length\": len(line.strip(\"#### \").strip()),\n",
    "                    }\n",
    "                )\n",
    "            elif line.startswith(\"##### \"):\n",
    "                headings.append(\n",
    "                    {\n",
    "                        \"type\": \"h5\",\n",
    "                        \"line_number\": line_number,\n",
    "                        \"content\": line.strip(\"##### \").strip(),\n",
    "                        \"length\": len(line.strip(\"##### \").strip()),\n",
    "                    }\n",
    "                )\n",
    "            elif line.startswith(\"###### \"):\n",
    "                headings.append(\n",
    "                    {\n",
    "                        \"type\": \"h6\",\n",
    "                        \"line_number\": line_number,\n",
    "                        \"content\": line.strip(\"###### \").strip(),\n",
    "                        \"length\": len(line.strip(\"###### \").strip()),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    return headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "def get_num_heads(h_elements):\n",
    "    \"\"\"\n",
    "    Return A list continas the length of each heading\n",
    "\n",
    "    Takes the heading info from `get_heads_info`\n",
    "    \"\"\"\n",
    "    #! Update this to work with the new dict structure\n",
    "    return list(map(len, h_elements.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def main_keyword_in_start(file_content, keyword, percent=10):\n",
    "    \"\"\"\n",
    "    Find if the Keyword in File Content\n",
    "    Default Percent is 10% of File Content\n",
    "    \"\"\"\n",
    "    if keyword in file_content[: int(len(file_content) * percent / 100)]:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
