{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fed96da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp seo_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b261f675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "from typing import Dict, List, Tuple\n",
    "from urllib.parse import urlparse\n",
    "from sqlmodel import Session, select, create_engine, SQLModel\n",
    "from seo_rat.article import Article\n",
    "from seo_rat.content_parser import extract_headers, remove_metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6303d188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def calculate_keyword_density(content: str, keyword: str) -> Dict:\n",
    "    \"\"\"Calculate keyword density and positions\"\"\"\n",
    "    content_lower = content.lower()\n",
    "    keyword_lower = keyword.lower()\n",
    "\n",
    "    # Find all positions\n",
    "    positions = []\n",
    "    pos = 0\n",
    "    while (pos := content_lower.find(keyword_lower, pos)) != -1:\n",
    "        positions.append(pos)\n",
    "        pos += 1\n",
    "\n",
    "    # Calculate density\n",
    "    total_words = len(content.split())\n",
    "    count = len(positions)\n",
    "    density = (count / total_words * 100) if total_words > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"keyword\": keyword,\n",
    "        \"count\": count,\n",
    "        \"density\": density,\n",
    "        \"positions\": positions,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9831a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | test\n",
    "from fastcore.test import test_eq\n",
    "from pprint import pprint\n",
    "\n",
    "# Read test file\n",
    "with open(\"../sample/example.md\", \"r\") as f:\n",
    "    content = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26381e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |test\n",
    "# Test keyword density\n",
    "density = calculate_keyword_density(content, \"Kareem\")\n",
    "\n",
    "test_eq(density[\"count\"] > 0, True)\n",
    "test_eq(\"density\" in density, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e868f584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def check_h1_count(\n",
    "    headers: List[Dict], title: str = None, is_quarto: bool = False\n",
    ") -> Dict:\n",
    "    h1s = [h for h in headers if h[\"type\"] == \"h1\"]\n",
    "\n",
    "    # For Quarto, title acts as H1\n",
    "    if is_quarto and title:\n",
    "        return {\"h1_count\": 1, \"has_single_h1\": True, \"h1_source\": \"title\"}\n",
    "\n",
    "    return {\"h1_count\": len(h1s), \"has_single_h1\": len(h1s) == 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c466725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | test\n",
    "# Test H1 count\n",
    "headers = extract_headers(\"../sample/example.md\")\n",
    "h1_check = check_h1_count(headers)\n",
    "test_eq(h1_check[\"h1_count\"], 2)\n",
    "test_eq(h1_check[\"has_single_h1\"], False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf146da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'This is me Kareem',\n",
      "  'length': 17,\n",
      "  'line_number': 15,\n",
      "  'type': 'h1'},\n",
      " {'content': 'This is Kareem Also',\n",
      "  'length': 19,\n",
      "  'line_number': 17,\n",
      "  'type': 'h1'},\n",
      " {'content': 'How do you know me!',\n",
      "  'length': 19,\n",
      "  'line_number': 21,\n",
      "  'type': 'h2'},\n",
      " {'content': 'oh no! iron man!', 'length': 16, 'line_number': 25, 'type': 'h2'},\n",
      " {'content': 'References', 'length': 10, 'line_number': 34, 'type': 'h2'},\n",
      " {'content': 'Books', 'length': 5, 'line_number': 42, 'type': 'h3'},\n",
      " {'content': 'nbdev is super cool!',\n",
      "  'length': 20,\n",
      "  'line_number': 48,\n",
      "  'type': 'h4'},\n",
      " {'content': 'Test Deriven Developement is a life changing!',\n",
      "  'length': 45,\n",
      "  'line_number': 50,\n",
      "  'type': 'h5'},\n",
      " {'content': 'I am an Love with best girl in the whole world!',\n",
      "  'length': 47,\n",
      "  'line_number': 52,\n",
      "  'type': 'h6'}]\n"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "pprint(headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add9d000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'h1_count': 2, 'has_single_h1': False}\n"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "pprint(h1_check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceb7d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def keyword_in_first_section(content: str, keyword: str, percent: int = 10) -> bool:\n",
    "    \"\"\"Check if keyword appears in first X% of content\"\"\"\n",
    "    section_length = int(len(content) * percent / 100)\n",
    "    return keyword.lower() in content[:section_length].lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1123e270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# | test\n",
    "in_start = keyword_in_first_section(content, \"Kareem\", percent=10)\n",
    "pprint(in_start)\n",
    "test_eq(in_start, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fafd76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def check_paragraph_length(content: str) -> Dict:\n",
    "    \"\"\"Check average paragraph length\"\"\"\n",
    "    paragraphs = [p.strip() for p in content.split(\"\\n\\n\") if p.strip()]\n",
    "    sentences_per_para = [len(p.split(\". \")) for p in paragraphs]\n",
    "    avg = sum(sentences_per_para) / len(sentences_per_para) if paragraphs else 0\n",
    "\n",
    "    return {\n",
    "        \"avg_sentences_per_paragraph\": avg,\n",
    "        \"is_optimal\": 2 <= avg <= 4,  # 2-4 sentences ideal\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f5c543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg sentences/paragraph: 1.2\n",
      "Optimal: False\n"
     ]
    }
   ],
   "source": [
    "# | test\n",
    "para_check = check_paragraph_length(content)\n",
    "print(f\"Avg sentences/paragraph: {para_check['avg_sentences_per_paragraph']:.1f}\")\n",
    "print(f\"Optimal: {para_check['is_optimal']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7778c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def keyword_in_metadata(metadata: Dict, keyword: str) -> Dict:\n",
    "    \"\"\"Check if keyword is in title, excerpt, description\"\"\"\n",
    "    return {\n",
    "        \"in_title\": keyword.lower() in str(metadata.get(\"title\", \"\")).lower(),\n",
    "        \"in_excerpt\": keyword.lower() in str(metadata.get(\"excerpt\", \"\")).lower(),\n",
    "        \"in_description\": keyword.lower()\n",
    "        in str(metadata.get(\"description\", \"\")).lower(),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c12c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in_description': False, 'in_excerpt': False, 'in_title': True}\n"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "from seo_rat.content_parser import parse_metadata\n",
    "\n",
    "metadata = parse_metadata(content)\n",
    "test_key_in_metadata = keyword_in_metadata(metadata, \"Kareem\")\n",
    "pprint(test_key_in_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bb4ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def keyword_in_alt_texts(images: List[Dict], keyword: str) -> bool:\n",
    "    \"\"\"Check if keyword appears in any image alt text\"\"\"\n",
    "    return any(keyword.lower() in img[\"alt_text\"].lower() for img in images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1600985b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'alt_text': 'Iron man photo', 'url': '~/assets/images/28.png'}]\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "from seo_rat.content_parser import extract_images\n",
    "\n",
    "images = extract_images(content)\n",
    "pprint(images)\n",
    "test_keyword_in_alt_texts = keyword_in_alt_texts(images, \"Kareem\")\n",
    "pprint(test_keyword_in_alt_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a9005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def analyze_header_distribution(headers: List[Dict]) -> Dict:\n",
    "    \"\"\"Analyze header hierarchy distribution\"\"\"\n",
    "    distribution = {}\n",
    "    for h in headers:\n",
    "        h_type = h[\"type\"]\n",
    "        distribution[h_type] = distribution.get(h_type, 0) + 1\n",
    "\n",
    "    total = len(headers)\n",
    "    percentages = {\n",
    "        k: (v / total * 100) if total > 0 else 0 for k, v in distribution.items()\n",
    "    }\n",
    "\n",
    "    return {\"counts\": distribution, \"percentages\": percentages}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3638374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'counts': {'h1': 2, 'h2': 3, 'h3': 1, 'h4': 1, 'h5': 1, 'h6': 1},\n",
      " 'percentages': {'h1': 22.22222222222222,\n",
      "                 'h2': 33.33333333333333,\n",
      "                 'h3': 11.11111111111111,\n",
      "                 'h4': 11.11111111111111,\n",
      "                 'h5': 11.11111111111111,\n",
      "                 'h6': 11.11111111111111}}\n"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "headers = extract_headers(\"../sample/example.md\")\n",
    "header_distribution = analyze_header_distribution(headers)\n",
    "pprint(header_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6453b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def detect_duplicate_content(\n",
    "    session: Session, file_path: str, similarity_threshold: float = 0.8\n",
    ") -> Dict:\n",
    "    \"\"\"Find similar articles by comparing content\"\"\"\n",
    "    from seo_rat.content_parser import (\n",
    "        remove_metadata,\n",
    "        normalize_text,\n",
    "        calculate_similarity,\n",
    "    )\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        current_content = normalize_text(remove_metadata(f.read()))\n",
    "\n",
    "    articles = session.exec(select(Article)).all()\n",
    "    similar = []\n",
    "\n",
    "    for article in articles:\n",
    "        if article.file_path == file_path:\n",
    "            continue\n",
    "\n",
    "        with open(article.file_path, \"r\") as f:\n",
    "            other_content = normalize_text(remove_metadata(f.read()))\n",
    "\n",
    "        similarity = calculate_similarity(current_content, other_content)\n",
    "\n",
    "        if similarity >= similarity_threshold:\n",
    "            similar.append({\"file_path\": article.file_path, \"similarity\": similarity})\n",
    "\n",
    "    return {\"has_duplicates\": len(similar) > 0, \"similar_articles\": similar}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2b0ba2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoReferencedTableError",
     "evalue": "Foreign key associated with column 'article.website_id' could not find table 'website' with which to generate a foreign key to target column 'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNoReferencedTableError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# | test\u001b[39;00m\n\u001b[32m      2\u001b[39m engine = create_engine(\u001b[33m\"\u001b[39m\u001b[33msqlite:///:memory:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mSQLModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Session(engine) \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# Create website\u001b[39;00m\n\u001b[32m      7\u001b[39m     website = Website(url=\u001b[33m\"\u001b[39m\u001b[33mhttps://test.com\u001b[39m\u001b[33m\"\u001b[39m, name=\u001b[33m\"\u001b[39m\u001b[33mTest\u001b[39m\u001b[33m\"\u001b[39m, lang=\u001b[33m\"\u001b[39m\u001b[33men\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/seo_rat/.venv/lib/python3.13/site-packages/sqlalchemy/sql/schema.py:5928\u001b[39m, in \u001b[36mMetaData.create_all\u001b[39m\u001b[34m(self, bind, tables, checkfirst)\u001b[39m\n\u001b[32m   5904\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_all\u001b[39m(\n\u001b[32m   5905\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5906\u001b[39m     bind: _CreateDropBind,\n\u001b[32m   5907\u001b[39m     tables: Optional[_typing_Sequence[Table]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5908\u001b[39m     checkfirst: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   5909\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5910\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create all tables stored in this metadata.\u001b[39;00m\n\u001b[32m   5911\u001b[39m \n\u001b[32m   5912\u001b[39m \u001b[33;03m    Conditional by default, will not attempt to recreate tables already\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   5926\u001b[39m \n\u001b[32m   5927\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5928\u001b[39m     \u001b[43mbind\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_run_ddl_visitor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5929\u001b[39m \u001b[43m        \u001b[49m\u001b[43mddl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSchemaGenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckfirst\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckfirst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtables\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtables\u001b[49m\n\u001b[32m   5930\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/seo_rat/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py:3260\u001b[39m, in \u001b[36mEngine._run_ddl_visitor\u001b[39m\u001b[34m(self, visitorcallable, element, **kwargs)\u001b[39m\n\u001b[32m   3253\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_ddl_visitor\u001b[39m(\n\u001b[32m   3254\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   3255\u001b[39m     visitorcallable: Type[InvokeDDLBase],\n\u001b[32m   3256\u001b[39m     element: SchemaVisitable,\n\u001b[32m   3257\u001b[39m     **kwargs: Any,\n\u001b[32m   3258\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3259\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.begin() \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[32m-> \u001b[39m\u001b[32m3260\u001b[39m         \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_run_ddl_visitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvisitorcallable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/seo_rat/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py:2467\u001b[39m, in \u001b[36mConnection._run_ddl_visitor\u001b[39m\u001b[34m(self, visitorcallable, element, **kwargs)\u001b[39m\n\u001b[32m   2453\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_ddl_visitor\u001b[39m(\n\u001b[32m   2454\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2455\u001b[39m     visitorcallable: Type[InvokeDDLBase],\n\u001b[32m   2456\u001b[39m     element: SchemaVisitable,\n\u001b[32m   2457\u001b[39m     **kwargs: Any,\n\u001b[32m   2458\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2459\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"run a DDL visitor.\u001b[39;00m\n\u001b[32m   2460\u001b[39m \n\u001b[32m   2461\u001b[39m \u001b[33;03m    This method is only here so that the MockConnection can change the\u001b[39;00m\n\u001b[32m   2462\u001b[39m \u001b[33;03m    options given to the visitor so that \"checkfirst\" is skipped.\u001b[39;00m\n\u001b[32m   2463\u001b[39m \n\u001b[32m   2464\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   2465\u001b[39m     \u001b[43mvisitorcallable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2466\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m2467\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtraverse_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/seo_rat/.venv/lib/python3.13/site-packages/sqlalchemy/sql/visitors.py:661\u001b[39m, in \u001b[36mExternalTraversal.traverse_single\u001b[39m\u001b[34m(self, obj, **kw)\u001b[39m\n\u001b[32m    659\u001b[39m meth = \u001b[38;5;28mgetattr\u001b[39m(v, \u001b[33m\"\u001b[39m\u001b[33mvisit_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % obj.__visit_name__, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    660\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m meth:\n\u001b[32m--> \u001b[39m\u001b[32m661\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/seo_rat/.venv/lib/python3.13/site-packages/sqlalchemy/sql/ddl.py:962\u001b[39m, in \u001b[36mSchemaGenerator.visit_metadata\u001b[39m\u001b[34m(self, metadata)\u001b[39m\n\u001b[32m    959\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    960\u001b[39m     tables = \u001b[38;5;28mlist\u001b[39m(metadata.tables.values())\n\u001b[32m--> \u001b[39m\u001b[32m962\u001b[39m collection = \u001b[43msort_tables_and_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtables\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_can_create_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    966\u001b[39m seq_coll = [\n\u001b[32m    967\u001b[39m     s\n\u001b[32m    968\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m metadata._sequences.values()\n\u001b[32m    969\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m s.column \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._can_create_sequence(s)\n\u001b[32m    970\u001b[39m ]\n\u001b[32m    972\u001b[39m event_collection = [t \u001b[38;5;28;01mfor\u001b[39;00m (t, fks) \u001b[38;5;129;01min\u001b[39;00m collection \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/seo_rat/.venv/lib/python3.13/site-packages/sqlalchemy/sql/ddl.py:1394\u001b[39m, in \u001b[36msort_tables_and_constraints\u001b[39m\u001b[34m(tables, filter_fn, extra_dependencies, _warn_for_cycles)\u001b[39m\n\u001b[32m   1391\u001b[39m         remaining_fkcs.add(fkc)\n\u001b[32m   1392\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1394\u001b[39m dependent_on = \u001b[43mfkc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreferred_table\u001b[49m\n\u001b[32m   1395\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dependent_on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m table:\n\u001b[32m   1396\u001b[39m     mutable_dependencies.add((dependent_on, table))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/seo_rat/.venv/lib/python3.13/site-packages/sqlalchemy/sql/schema.py:4799\u001b[39m, in \u001b[36mForeignKeyConstraint.referred_table\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   4789\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m   4790\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreferred_table\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Table:\n\u001b[32m   4791\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"The :class:`_schema.Table` object to which this\u001b[39;00m\n\u001b[32m   4792\u001b[39m \u001b[33;03m    :class:`_schema.ForeignKeyConstraint` references.\u001b[39;00m\n\u001b[32m   4793\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4797\u001b[39m \n\u001b[32m   4798\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4799\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43melements\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumn\u001b[49m.table\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/seo_rat/.venv/lib/python3.13/site-packages/sqlalchemy/util/langhelpers.py:1226\u001b[39m, in \u001b[36m_memoized_property.__get__\u001b[39m\u001b[34m(self, obj, cls)\u001b[39m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1226\u001b[39m obj.\u001b[34m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m.\u001b[34m__name__\u001b[39m] = result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/seo_rat/.venv/lib/python3.13/site-packages/sqlalchemy/sql/schema.py:3199\u001b[39m, in \u001b[36mForeignKey.column\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3189\u001b[39m \u001b[38;5;129m@util\u001b[39m.ro_memoized_property\n\u001b[32m   3190\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcolumn\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Column[Any]:\n\u001b[32m   3191\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the target :class:`_schema.Column` referenced by this\u001b[39;00m\n\u001b[32m   3192\u001b[39m \u001b[33;03m    :class:`_schema.ForeignKey`.\u001b[39;00m\n\u001b[32m   3193\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3196\u001b[39m \n\u001b[32m   3197\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3199\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_resolve_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/seo_rat/.venv/lib/python3.13/site-packages/sqlalchemy/sql/schema.py:3222\u001b[39m, in \u001b[36mForeignKey._resolve_column\u001b[39m\u001b[34m(self, raiseerr)\u001b[39m\n\u001b[32m   3220\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raiseerr:\n\u001b[32m   3221\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3222\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc.NoReferencedTableError(\n\u001b[32m   3223\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mForeign key associated with column \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.parent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m could not find \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3225\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtable \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtablekey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m with which to generate a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mforeign key to target column \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   3227\u001b[39m         tablekey,\n\u001b[32m   3228\u001b[39m     )\n\u001b[32m   3229\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m parenttable.key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m parenttable.metadata:\n\u001b[32m   3230\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raiseerr:\n",
      "\u001b[31mNoReferencedTableError\u001b[39m: Foreign key associated with column 'article.website_id' could not find table 'website' with which to generate a foreign key to target column 'id'"
     ]
    }
   ],
   "source": [
    "# | test\n",
    "engine = create_engine(\"sqlite:///:memory:\")\n",
    "SQLModel.metadata.create_all(engine)\n",
    "\n",
    "with Session(engine) as session:\n",
    "    # Create website\n",
    "    website = Website(url=\"https://test.com\", name=\"Test\", lang=\"en\")\n",
    "    session.add(website)\n",
    "    session.commit()\n",
    "    session.refresh(website)\n",
    "\n",
    "    # Create a second similar file\n",
    "    with open(\"../sample/example2.md\", \"w\") as f:\n",
    "        (f.write(content),)\n",
    "    article1 = insert_article(session, website.id, \"../sample/example.md\")\n",
    "    article2 = insert_article(session, website.id, \"../sample/example2.md\")\n",
    "\n",
    "    result = detect_duplicate_content(session, \"../sample/example.md\")\n",
    "    test_eq(result[\"has_duplicates\"], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37218e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def analyze_keyword_cannibalization(session: Session, keyword: str) -> Dict:\n",
    "    \"\"\"Find articles competing for same keyword\"\"\"\n",
    "\n",
    "    articles = session.exec(\n",
    "        select(Article).where(Article.focus_keyword == keyword)\n",
    "    ).all()\n",
    "\n",
    "    if len(articles) <= 1:\n",
    "        return {\n",
    "            \"has_cannibalization\": False,\n",
    "            \"keyword\": keyword,\n",
    "            \"count\": len(articles),\n",
    "        }\n",
    "\n",
    "    results = []\n",
    "    for article in articles:\n",
    "        with open(article.file_path, \"r\") as f:\n",
    "            content = remove_metadata(f.read())\n",
    "\n",
    "        density = calculate_keyword_density(content, keyword)\n",
    "        results.append(\n",
    "            {\n",
    "                \"file_path\": article.file_path,\n",
    "                \"density\": density[\"density\"],\n",
    "                \"count\": density[\"count\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"has_cannibalization\": True,\n",
    "        \"keyword\": keyword,\n",
    "        \"count\": len(articles),\n",
    "        \"articles\": results,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c152c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'session' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# | hide\u001b[39;00m\n\u001b[32m      3\u001b[39m test_analyze_keyword_cannibalization = analyze_keyword_cannibalization(\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43msession\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33mKareem\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m )\n\u001b[32m      6\u001b[39m pprint(test_analyze_keyword_cannibalization)\n",
      "\u001b[31mNameError\u001b[39m: name 'session' is not defined"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "\n",
    "test_analyze_keyword_cannibalization = analyze_keyword_cannibalization(\n",
    "    session, \"Kareem\"\n",
    ")\n",
    "pprint(test_analyze_keyword_cannibalization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5ed414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def analyze_content_groups(session: Session, similarity_threshold: float = 0.8) -> Dict:\n",
    "    \"\"\"Group similar articles together\"\"\"\n",
    "    from seo_rat.content_parser import (\n",
    "        remove_metadata,\n",
    "        normalize_text,\n",
    "        calculate_similarity,\n",
    "    )\n",
    "\n",
    "    articles = session.exec(select(Article)).all()\n",
    "    groups = []\n",
    "    processed = set()\n",
    "\n",
    "    for article in articles:\n",
    "        if article.id in processed:\n",
    "            continue\n",
    "\n",
    "        with open(article.file_path, \"r\") as f:\n",
    "            main_content = normalize_text(remove_metadata(f.read()))\n",
    "\n",
    "        group = {\"main_article\": article.file_path, \"similar_articles\": []}\n",
    "\n",
    "        for other in articles:\n",
    "            if other.id == article.id or other.id in processed:\n",
    "                continue\n",
    "\n",
    "            with open(other.file_path, \"r\") as f:\n",
    "                other_content = normalize_text(remove_metadata(f.read()))\n",
    "\n",
    "            similarity = calculate_similarity(main_content, other_content)\n",
    "\n",
    "            if similarity >= similarity_threshold:\n",
    "                group[\"similar_articles\"].append(\n",
    "                    {\"file_path\": other.file_path, \"similarity\": similarity}\n",
    "                )\n",
    "                processed.add(other.id)\n",
    "\n",
    "        if group[\"similar_articles\"]:\n",
    "            groups.append(group)\n",
    "            processed.add(article.id)\n",
    "\n",
    "    return {\n",
    "        \"total_articles\": len(articles),\n",
    "        \"groups\": groups,\n",
    "        \"duplicate_groups\": len(groups),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef08c6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'session' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# | hide\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m test_analyze_content_groups = analyze_content_groups(\u001b[43msession\u001b[49m, \u001b[32m0.8\u001b[39m)\n\u001b[32m      4\u001b[39m pprint(test_analyze_content_groups)\n",
      "\u001b[31mNameError\u001b[39m: name 'session' is not defined"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "\n",
    "test_analyze_content_groups = analyze_content_groups(session, 0.8)\n",
    "pprint(test_analyze_content_groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af50f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "def get_num_heads(h_elements):\n",
    "    \"\"\"\n",
    "    Return A list continas the length of each heading\n",
    "\n",
    "    Takes the heading info from `get_heads_info`\n",
    "    \"\"\"\n",
    "    #! Update this to work with the new dict structure\n",
    "    return list(map(len, h_elements.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807dc169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | test\n",
    "# Test detect_duplicate_content (needs session)\n",
    "from sqlmodel import create_engine, Session, SQLModel\n",
    "from seo_rat.models import Website\n",
    "from seo_rat.article import Article, insert_article\n",
    "import tempfile\n",
    "\n",
    "engine = create_engine(\"sqlite:///:memory:\")\n",
    "SQLModel.metadata.create_all(engine)\n",
    "\n",
    "with Session(engine) as session:\n",
    "    # Create test articles\n",
    "    website = Website(url=\"https://test.com\", name=\"Test\", lang=\"en\")\n",
    "    session.add(website)\n",
    "    session.commit()\n",
    "\n",
    "    # Create temp files with similar content\n",
    "    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".md\", delete=False) as f1:\n",
    "        f1.write(content)\n",
    "        path1 = f1.name\n",
    "\n",
    "    article1 = insert_article(session, website.id, path1)\n",
    "\n",
    "    result = detect_duplicate_content(session, path1)\n",
    "    test_eq(\"has_duplicates\" in result, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5de0dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
